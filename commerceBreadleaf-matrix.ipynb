{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1CZk9PEjqEJY4NEkz/XkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vajihe-ameri/predict-software-bugs-in-java-classes/blob/main/commerceBreadleaf-matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "H8Cz6wdlnY4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn pandas\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7moBUzj9nZnR",
        "outputId": "fa385f47-a57a-4159-a929-e5388c2f9db7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=474d5bf3e69d4f08de751ba0e5553fff5892a98509694117660c2ead21f69ada\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset"
      ],
      "metadata": {
        "id": "_0ENIcE_nbos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive \n",
        "drive = drive.mount('/content/drive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUvJN9yenfMB",
        "outputId": "b6fbaf6f-bfc9-4f57-c1a8-2c2f58dbc4e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call algorithms from sklearn"
      ],
      "metadata": {
        "id": "VoCc7KGwno_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "'''Read data from CSV with Pandas'''\n",
        "ignored_cols = ['Hash', 'LongName']\n",
        "\n",
        "file = \"drive/MyDrive/class.csv\"\n",
        "cols = list(pd.read_csv(file, nrows =1).dropna(axis='columns', how='all'))\n",
        "cols.remove('Hash')\n",
        "cols.remove('LongName')\n",
        "\n",
        "df = pd.read_csv(file, usecols = cols)\n",
        "df = df.T.drop_duplicates().T\n",
        "normalized_df=(df-df.mean())/df.std()\n",
        "\n",
        "'''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.25)\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "'''First 4 colums are the data to train'''\n",
        "features = df.columns[:-1]\n",
        "\n",
        "'''Species names to factor'''\n",
        "y, bugs = pd.factorize(train['Number of Bugs'])\n",
        "\n",
        "# random forest\n",
        "'''Create random forest classifier'''\n",
        "model = RandomForestClassifier(n_jobs=2, max_depth = 10, random_state = 40)\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Random forest')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "\n",
        "# logistic regression\n",
        "'''Create logistic regression classifier'''  \n",
        "model1 = LogisticRegression()\n",
        "model2 = LogisticRegression(solver='sag', penalty='l2',n_jobs=-1, random_state=10)\n",
        "model3 = LogisticRegression(solver='saga', penalty='l2',n_jobs=-1, random_state=20)\n",
        "model4 = LogisticRegression(solver='liblinear', penalty='l1',n_jobs=-1, random_state=0)\n",
        "model5 = LogisticRegression(solver='liblinear', penalty='l2',n_jobs=-1, random_state=90)\n",
        "model6 = LogisticRegression(solver='lbfgs', penalty='l2',n_jobs=-1, random_state=50)\n",
        "model7 = LogisticRegression(solver='newton-cg', penalty='l2',n_jobs=-1, random_state=90)\n",
        "\n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "model6.fit(train[features], y)\n",
        "model7.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "preds6 = bugs.values[model6.predict(test[features])]\n",
        "preds7 = bugs.values[model7.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "cr6 = confusion_matrix(actual_classes, preds6)\n",
        "cr7 = confusion_matrix(actual_classes, preds7)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "tn6 = cr6[1,0]\n",
        "fn6 = cr6[1,1]\n",
        "tn7 = cr7[1,0]\n",
        "fn7 = cr7[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "bugs_number6 = tn6 + fn6\n",
        "bugs_number7 = tn7 + fn7\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "f1_weighted6 = f1_score(actual_classes, preds6, average = 'weighted')\n",
        "f1_weighted7 = f1_score(actual_classes, preds7, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "f1_macro6 = f1_score(actual_classes, preds6, average = 'macro')\n",
        "f1_macro7 = f1_score(actual_classes, preds7, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "f1_micro6 = f1_score(actual_classes, preds6, average = 'micro')\n",
        "f1_micro7 = f1_score(actual_classes, preds7, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "f1_score_weighted6 = \"%.2f\"%round(f1_weighted6, 2)\n",
        "f1_score_weighted7 = \"%.2f\"%round(f1_weighted7, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "f1_score_macro6 = \"%.2f\"%round(f1_macro6, 2)\n",
        "f1_score_macro7 = \"%.2f\"%round(f1_macro7, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "f1_score_micro6 = \"%.2f\"%round(f1_micro6, 2)\n",
        "f1_score_micro7 = \"%.2f\"%round(f1_micro7, 2)\n",
        "\n",
        "print('Logistic regression')\n",
        "head = PrettyTable(['random_state', 'solver', 'penalty', 'n_jobs', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['10', 'sag', 'l2', '-1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['20', 'saga', 'l2', '-1', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['0', 'liblinear', 'l1', '-1', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['90', 'liblinear', 'l2', '-1', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "head.add_row(['50', 'lbfgs', 'l2', '-1', cr6, f1_score_weighted6, f1_score_macro6, f1_score_micro6, bugs_number6]) \n",
        "head.add_row(['90', 'newton-cg', 'l2', '-1', cr7, f1_score_weighted7, f1_score_macro7, f1_score_micro7, bugs_number7]) \n",
        "print(head)\n",
        "\n",
        "# naive bayes\n",
        "'''Create naive bayes classifier'''\n",
        "model = GaussianNB()\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Naive bayes')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "\n",
        "# Artificial Neural Network\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Artificial neural network')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "\n",
        "# Multi-Layer Perceptron Neural Network\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model = MLPClassifier()\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Multi layer perceptron neural network')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "\n",
        "# Support vector machine\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model = SVC(C=1.0, random_state=1, kernel='linear')\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Support vector machine')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "\n",
        "# decision tree\n",
        "'''Create decision tree classifier'''    \n",
        "model = tree.DecisionTreeClassifier(max_depth = 1,  random_state = 90)\n",
        "  \n",
        "'''Train and test'''\n",
        "model.fit(train[features], y)\n",
        "preds = bugs.values[model.predict(test[features])]\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "cr = confusion_matrix(actual_classes, preds)\n",
        "tn = cr[1,0]\n",
        "fn = cr[1,1]\n",
        "bugs_number = tn + fn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "  \n",
        "print('Decision tree')\n",
        "head = PrettyTable(['confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row([cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_KcVobJnv1d",
        "outputId": "ff618f16-5e86-40f6-9af8-cbd42b8f26fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|    [[130   4]    |        0.85       |      0.56      |      0.88      |      16     |\n",
            "|    [ 14   2]]    |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state |   solver  | penalty | n_jobs | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |           |         |        |  [[132   2   0]  |        0.84       |      0.31      |      0.88      |      15     |\n",
            "|              |           |         |        |   [ 15   0   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      10      |    sag    |    l2   |   -1   |  [[134   0   0]  |        0.85       |      0.32      |      0.89      |      15     |\n",
            "|              |           |         |        |   [ 15   0   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      20      |    saga   |    l2   |   -1   |  [[134   0   0]  |        0.85       |      0.32      |      0.89      |      15     |\n",
            "|              |           |         |        |   [ 15   0   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      0       | liblinear |    l1   |   -1   |  [[130   4   0]  |        0.86       |      0.37      |      0.88      |      15     |\n",
            "|              |           |         |        |   [ 13   2   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      90      | liblinear |    l2   |   -1   |  [[128   6   0]  |        0.85       |      0.37      |      0.87      |      15     |\n",
            "|              |           |         |        |   [ 13   2   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      50      |   lbfgs   |    l2   |   -1   |  [[132   2   0]  |        0.84       |      0.31      |      0.88      |      15     |\n",
            "|              |           |         |        |   [ 15   0   1]  |                   |                |                |             |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |             |\n",
            "|      90      | newton-cg |    l2   |   -1   |    [[127   7]    |        0.84       |      0.54      |      0.86      |      16     |\n",
            "|              |           |         |        |    [ 14   2]]    |                   |                |                |             |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "Naive bayes\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|     [[68 66]     |        0.62       |      0.47      |      0.54      |      16     |\n",
            "|     [ 3 13]]     |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "Artificial neural network\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|    [[134   0]    |        0.84       |      0.47      |      0.89      |      16     |\n",
            "|    [ 16   0]]    |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "Multi layer perceptron neural network\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|  [[121  13   0]  |        0.82       |      0.34      |      0.82      |      15     |\n",
            "|   [ 13   2   1]  |                   |                |                |             |\n",
            "|  [  0   0   0]]  |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "Support vector machine\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|    [[127   7]    |        0.84       |      0.54      |      0.86      |      16     |\n",
            "|    [ 14   2]]    |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "Decision tree\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "| confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n",
            "|    [[134   0]    |        0.84       |      0.47      |      0.89      |      16     |\n",
            "|    [ 16   0]]    |                   |                |                |             |\n",
            "+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        }
      ]
    }
  ]
}
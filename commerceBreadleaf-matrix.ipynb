{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4PHcUYJD9wYiMqha1PeUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vajihe-ameri/predict-software-bugs-in-java-classes/blob/main/commerceBreadleaf-matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "H8Cz6wdlnY4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn pandas\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7moBUzj9nZnR",
        "outputId": "dfd94544-b92d-4d4e-ca50-6cb7666fd624"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=dbc9e5aaa5114932311bc6233b21f4229e9a188c97671d76eea69c44817ae6a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset"
      ],
      "metadata": {
        "id": "_0ENIcE_nbos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive \n",
        "drive = drive.mount('/content/drive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUvJN9yenfMB",
        "outputId": "5e62b29d-e47d-454f-f82e-4659a081407a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call algorithms from sklearn"
      ],
      "metadata": {
        "id": "VoCc7KGwno_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "'''Read data from CSV with Pandas'''\n",
        "ignored_cols = ['Hash', 'LongName']\n",
        "\n",
        "file = \"drive/MyDrive/class.csv\"\n",
        "cols = list(pd.read_csv(file, nrows =1).dropna(axis='columns', how='all'))\n",
        "cols.remove('Hash')\n",
        "cols.remove('LongName')\n",
        "\n",
        "df = pd.read_csv(file, usecols = cols)\n",
        "df = df.T.drop_duplicates().T\n",
        "normalized_df=(df-df.mean())/df.std()\n",
        "\n",
        "'''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.25)\n",
        "actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "'''First 4 colums are the data to train'''\n",
        "features = df.columns[:-1]\n",
        "\n",
        "'''Species names to factor'''\n",
        "y, bugs = pd.factorize(train['Number of Bugs'])\n",
        "\n",
        "# random forest\n",
        "'''Create random forest classifier'''\n",
        "model1 = RandomForestClassifier()\n",
        "model2 = RandomForestClassifier(n_estimators=100, criterion = 'gini', max_depth = 1, random_state = 80)\n",
        "model3 = RandomForestClassifier(n_estimators=90, criterion = 'entropy' , max_depth = 10, random_state = 50)\n",
        "model4 = RandomForestClassifier(n_estimators=50, criterion = 'entropy', max_depth = 20, random_state = 60)\n",
        "model5 = RandomForestClassifier(n_estimators=1, criterion = 'gini', max_depth = 30, random_state = 40)\n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "print('Random forest')\n",
        "head = PrettyTable(['random_state', 'n_estimatorsint', 'criterion', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['80', '10', 'gini', '1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['50', '100', 'entropy', '10', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['60', '50', 'entropy', '20', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['40', '1', 'gini', '30', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "print(head)\n",
        "\n",
        "# logistic regression\n",
        "'''Create logistic regression classifier'''  \n",
        "model1 = LogisticRegression()\n",
        "model2 = LogisticRegression(solver='sag', penalty='l2',n_jobs=-1, random_state=10)\n",
        "model3 = LogisticRegression(solver='saga', penalty='l2',n_jobs=-1, random_state=20)\n",
        "model4 = LogisticRegression(solver='liblinear', penalty='l1',n_jobs=-1, random_state=0)\n",
        "model5 = LogisticRegression(solver='liblinear', penalty='l2',n_jobs=-1, random_state=90)\n",
        "model6 = LogisticRegression(solver='lbfgs', penalty='l2',n_jobs=-1, random_state=50)\n",
        "model7 = LogisticRegression(solver='newton-cg', penalty='l2',n_jobs=-1, random_state=90)\n",
        "\n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "model6.fit(train[features], y)\n",
        "model7.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "preds6 = bugs.values[model6.predict(test[features])]\n",
        "preds7 = bugs.values[model7.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "cr6 = confusion_matrix(actual_classes, preds6)\n",
        "cr7 = confusion_matrix(actual_classes, preds7)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "tn6 = cr6[1,0]\n",
        "fn6 = cr6[1,1]\n",
        "tn7 = cr7[1,0]\n",
        "fn7 = cr7[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "bugs_number6 = tn6 + fn6\n",
        "bugs_number7 = tn7 + fn7\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "f1_weighted6 = f1_score(actual_classes, preds6, average = 'weighted')\n",
        "f1_weighted7 = f1_score(actual_classes, preds7, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "f1_macro6 = f1_score(actual_classes, preds6, average = 'macro')\n",
        "f1_macro7 = f1_score(actual_classes, preds7, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "f1_micro6 = f1_score(actual_classes, preds6, average = 'micro')\n",
        "f1_micro7 = f1_score(actual_classes, preds7, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "f1_score_weighted6 = \"%.2f\"%round(f1_weighted6, 2)\n",
        "f1_score_weighted7 = \"%.2f\"%round(f1_weighted7, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "f1_score_macro6 = \"%.2f\"%round(f1_macro6, 2)\n",
        "f1_score_macro7 = \"%.2f\"%round(f1_macro7, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "f1_score_micro6 = \"%.2f\"%round(f1_micro6, 2)\n",
        "f1_score_micro7 = \"%.2f\"%round(f1_micro7, 2)\n",
        "\n",
        "print('Logistic regression')\n",
        "head = PrettyTable(['random_state', 'solver', 'penalty', 'n_jobs', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['10', 'sag', 'l2', '-1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['20', 'saga', 'l2', '-1', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['0', 'liblinear', 'l1', '-1', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['90', 'liblinear', 'l2', '-1', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "head.add_row(['50', 'lbfgs', 'l2', '-1', cr6, f1_score_weighted6, f1_score_macro6, f1_score_micro6, bugs_number6]) \n",
        "head.add_row(['90', 'newton-cg', 'l2', '-1', cr7, f1_score_weighted7, f1_score_macro7, f1_score_micro7, bugs_number7]) \n",
        "print(head)\n",
        "\n",
        "# naive bayes\n",
        "'''Create naive bayes classifier'''\n",
        "model1 = GaussianNB()\n",
        "model2 = GaussianNB(var_smoothing = 1e-11)\n",
        "model3 = GaussianNB(var_smoothing = 1e-09)\n",
        "model4 = GaussianNB(var_smoothing = 1e-10)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "\n",
        "print('Naive bayes')\n",
        "head = PrettyTable(['var_smoothing', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['1e-11', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['1e-9', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['1e-10', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "print(head)\n",
        "\n",
        "\n",
        "# Multi-Layer Perceptron Neural Network\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model1 = MLPClassifier()\n",
        "model2 = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(5, 2), activation = 'tanh', random_state=10)\n",
        "model3 = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(150, 100, 50), activation = 'logistic',random_state=1)\n",
        "model4 = MLPClassifier(solver='adam', alpha=0.05, hidden_layer_sizes=(100, 50, 30), activation = 'relu', random_state=90)\n",
        "model5 = MLPClassifier(solver='lbfgs', alpha=0.0001, hidden_layer_sizes=(120, 80, 40), activation = 'identity', random_state=40)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "print('Multi layer perceptron neural network')\n",
        "head = PrettyTable(['random_state', 'activation', 'solver', 'hidden_layer_sizestuple', 'alpha', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['10', 'tanh', 'lbfgs', '(5, 2)', '0.01', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['1', 'logistic', 'sgd', '(150, 100, 50)', 'le-5', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['90', 'relu', 'adam', '(100, 50, 30)', '0.05', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['40', 'identity', 'lbfgs', '(120, 80, 40)', '0.0001', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "print(head)\n",
        "  \n",
        "\n",
        "# Support vector machine\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model1 = SVC()\n",
        "model2 = SVC(kernel='sigmoid', C=100, gamma=1, random_state=85)\n",
        "model3 = SVC(kernel='poly', C=10, gamma=0.1, random_state=12)\n",
        "model4 = SVC(kernel='rbf', C=0.1, gamma=0.01, random_state=15)\n",
        "model5 = SVC(kernel='linear', C=1, gamma=0.001, random_state=74)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "print('Support vector machine')\n",
        "head = PrettyTable(['random_state', 'c', 'gamma', 'kernel', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['85', '100', '1', 'sigmoid', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['12', '10', '0.1', 'poly', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['15', '0.01', '0.01', 'rbf', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['74', '1', '0.001', 'linear', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "print(head)\n",
        "\n",
        "\n",
        "# decision tree\n",
        "print('Decision tree')\n",
        "head = PrettyTable(['random_state', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "max_depth_range = list(range(1, 15))\n",
        "for depth in max_depth_range:\n",
        "  '''Create decision tree classifier'''    \n",
        "  model = tree.DecisionTreeClassifier(max_depth = depth,  random_state = 90)\n",
        "  \n",
        "  '''Train and test'''\n",
        "  model.fit(train[features], y)\n",
        "  preds = bugs.values[model.predict(test[features])]\n",
        "\n",
        "  cr = confusion_matrix(actual_classes, preds)\n",
        "  tn = cr[1,0]\n",
        "  fn = cr[1,1]\n",
        "  bugs_number = tn + fn\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "  f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "  f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "\n",
        "  f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "  f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "  f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "\n",
        "  head.add_row(['90', depth, cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_KcVobJnv1d",
        "outputId": "f40c64c8-8a0b-42e6-da05-7b9fef677070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state | n_estimatorsint | criterion | max_depth | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |                 |           |           |    [[132  10]    |        0.89       |      0.47      |      0.88      |      8      |\n",
            "|              |                 |           |           |    [  8   0]]    |                   |                |                |             |\n",
            "|      80      |        10       |    gini   |     1     |    [[142   0]    |        0.92       |      0.49      |      0.95      |      8      |\n",
            "|              |                 |           |           |    [  8   0]]    |                   |                |                |             |\n",
            "|      50      |       100       |  entropy  |     10    |    [[138   4]    |        0.91       |      0.48      |      0.92      |      8      |\n",
            "|              |                 |           |           |    [  8   0]]    |                   |                |                |             |\n",
            "|      60      |        50       |  entropy  |     20    |    [[133   9]    |        0.89       |      0.47      |      0.89      |      8      |\n",
            "|              |                 |           |           |    [  8   0]]    |                   |                |                |             |\n",
            "|      40      |        1        |    gini   |     30    |    [[132  10]    |        0.90       |      0.52      |      0.89      |      8      |\n",
            "|              |                 |           |           |    [  7   1]]    |                   |                |                |             |\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state |   solver  | penalty | n_jobs | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |           |         |        |    [[138   4]    |        0.91       |      0.48      |      0.92      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      10      |    sag    |    l2   |   -1   |    [[141   1]    |        0.92       |      0.48      |      0.94      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      20      |    saga   |    l2   |   -1   |    [[140   2]    |        0.91       |      0.48      |      0.93      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      0       | liblinear |    l1   |   -1   |    [[134   8]    |        0.89       |      0.47      |      0.89      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      90      | liblinear |    l2   |   -1   |    [[133   9]    |        0.89       |      0.47      |      0.89      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      50      |   lbfgs   |    l2   |   -1   |    [[138   4]    |        0.91       |      0.48      |      0.92      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      90      | newton-cg |    l2   |   -1   |    [[133   9]    |        0.89       |      0.47      |      0.89      |      8      |\n",
            "|              |           |         |        |    [  8   0]]    |                   |                |                |             |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "Naive bayes\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| var_smoothing | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|               |     [[91 51]     |        0.74       |      0.48      |      0.65      |      8      |\n",
            "|               |     [ 2  6]]     |                   |                |                |             |\n",
            "|     1e-11     |     [[60 82]     |        0.57       |      0.37      |      0.45      |      8      |\n",
            "|               |     [ 1  7]]     |                   |                |                |             |\n",
            "|      1e-9     |     [[91 51]     |        0.74       |      0.48      |      0.65      |      8      |\n",
            "|               |     [ 2  6]]     |                   |                |                |             |\n",
            "|     1e-10     |     [[78 64]     |        0.67       |      0.43      |      0.56      |      8      |\n",
            "|               |     [ 2  6]]     |                   |                |                |             |\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi layer perceptron neural network\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state | activation | solver | hidden_layer_sizestuple | alpha  | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |            |        |                         |        |    [[129  13]    |        0.89       |      0.55      |      0.87      |      8      |\n",
            "|              |            |        |                         |        |    [  6   2]]    |                   |                |                |             |\n",
            "|      10      |    tanh    | lbfgs  |          (5, 2)         |  0.01  |    [[142   0]    |        0.92       |      0.49      |      0.95      |      8      |\n",
            "|              |            |        |                         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      1       |  logistic  |  sgd   |      (150, 100, 50)     |  le-5  |    [[142   0]    |        0.92       |      0.49      |      0.95      |      8      |\n",
            "|              |            |        |                         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      90      |    relu    |  adam  |      (100, 50, 30)      |  0.05  |    [[139   3]    |        0.91       |      0.48      |      0.93      |      8      |\n",
            "|              |            |        |                         |        |    [  8   0]]    |                   |                |                |             |\n",
            "|      40      |  identity  | lbfgs  |      (120, 80, 40)      | 0.0001 |    [[142   0]    |        0.92       |      0.49      |      0.95      |      8      |\n",
            "|              |            |        |                         |        |    [  8   0]]    |                   |                |                |             |\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTHbq1u8A3AZ1BvgBUe/xT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vajihe-ameri/predict-software-bugs-in-java-classes/blob/main/tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "H8Cz6wdlnY4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn pandas\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7moBUzj9nZnR",
        "outputId": "1647b06f-df9b-4ba1-c491-a315df2486a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=d67bc05f0317d6eb69298800841f994893a6cd1b360647e9737320dac38c5e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset"
      ],
      "metadata": {
        "id": "_0ENIcE_nbos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive \n",
        "drive = drive.mount('/content/drive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUvJN9yenfMB",
        "outputId": "6f72f46e-963d-4738-db1f-9081cad8003d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call algorithms from sklearntrain_featurestrain_fea"
      ],
      "metadata": {
        "id": "AbjoU_t7Y8D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "e6c75lOWY9cB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest"
      ],
      "metadata": {
        "id": "i7g4skTHZSfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random forest:')\n",
        "projects = ['elasticsearch']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "  df.info()\n",
        "  df.describe(include=\"all\")\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "  actual_classes = test.iloc[:,-1:]\n",
        "\n",
        "  normalized_df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "\n",
        "  '''First 4 colums are the data to train'''\n",
        "  features = df.columns[:-1]\n",
        "\n",
        "  '''Species names to factor'''\n",
        "  y, bugs = pd.factorize(train['Number of Bugs'])\n",
        "  \n",
        "  '''Create random forest classifier'''\n",
        "  model1 = RandomForestClassifier()\n",
        "  model2 = RandomForestClassifier(n_estimators=100, criterion = 'gini', max_depth = 1, random_state = 80)\n",
        "  model3 = RandomForestClassifier(n_estimators=90, criterion = 'entropy' , max_depth = 10, random_state = 50)\n",
        "  model4 = RandomForestClassifier(n_estimators=50, criterion = 'entropy', max_depth = 20, random_state = 60)\n",
        "  model5 = RandomForestClassifier(n_estimators=1, criterion = 'gini', max_depth = 30, random_state = 40)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train[features], y)\n",
        "  model2.fit(train[features], y)\n",
        "  model3.fit(train[features], y)\n",
        "  model4.fit(train[features], y)\n",
        "  model5.fit(train[features], y)\n",
        "\n",
        "  preds1 = bugs.values[model1.predict(test[features])]\n",
        "  preds2 = bugs.values[model2.predict(test[features])]\n",
        "  preds3 = bugs.values[model3.predict(test[features])]\n",
        "  preds4 = bugs.values[model4.predict(test[features])]\n",
        "  preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "  cr1 = confusion_matrix(actual_classes, preds1)\n",
        "  cr2 = confusion_matrix(actual_classes, preds2)\n",
        "  cr3 = confusion_matrix(actual_classes, preds3)\n",
        "  cr4 = confusion_matrix(actual_classes, preds4)\n",
        "  cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "  tn1 = cr1[1,0]\n",
        "  fn1 = cr1[1,1]\n",
        "  tn2 = cr2[1,0]\n",
        "  fn2 = cr2[1,1]\n",
        "  tn3 = cr3[1,0]\n",
        "  fn3 = cr3[1,1]\n",
        "  tn4 = cr4[1,0]\n",
        "  fn4 = cr4[1,1]\n",
        "  tn5 = cr5[1,0]\n",
        "  fn5 = cr5[1,1]\n",
        "\n",
        "  bugs_number1 = tn1 + fn1\n",
        "  bugs_number2 = tn2 + fn2\n",
        "  bugs_number3 = tn3 + fn3\n",
        "  bugs_number4 = tn4 + fn4\n",
        "  bugs_number5 = tn5 + fn5\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "  f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "  f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "  f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "  f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "  f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "  f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "  head = PrettyTable(['random_state', 'n_estimatorsint', 'criterion', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "  head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "  head.add_row(['80', '10', 'gini', '1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "  head.add_row(['50', '100', 'entropy', '10', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "  head.add_row(['60', '50', 'entropy', '20', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "  head.add_row(['40', '1', 'gini', '30', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ9PWz8dZTSM",
        "outputId": "7a348d9f-c3a1-49c7-ef62-863d2408df7f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest:\n",
            "Project: elasticsearch\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24994 entries, 0 to 24993\n",
            "Data columns (total 86 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   CC                                 24994 non-null  float64\n",
            " 1   CCL                                24994 non-null  float64\n",
            " 2   CCO                                24994 non-null  float64\n",
            " 3   CI                                 24994 non-null  float64\n",
            " 4   CLC                                24994 non-null  float64\n",
            " 5   CLLC                               24994 non-null  float64\n",
            " 6   LDC                                24994 non-null  float64\n",
            " 7   LLDC                               24994 non-null  float64\n",
            " 8   LCOM5                              24994 non-null  float64\n",
            " 9   NL                                 24994 non-null  float64\n",
            " 10  NLE                                24994 non-null  float64\n",
            " 11  WMC                                24994 non-null  float64\n",
            " 12  CBO                                24994 non-null  float64\n",
            " 13  CBOI                               24994 non-null  float64\n",
            " 14  NII                                24994 non-null  float64\n",
            " 15  NOI                                24994 non-null  float64\n",
            " 16  RFC                                24994 non-null  float64\n",
            " 17  AD                                 24994 non-null  float64\n",
            " 18  CD                                 24994 non-null  float64\n",
            " 19  CLOC                               24994 non-null  float64\n",
            " 20  DLOC                               24994 non-null  float64\n",
            " 21  PDA                                24994 non-null  float64\n",
            " 22  PUA                                24994 non-null  float64\n",
            " 23  TCD                                24994 non-null  float64\n",
            " 24  TCLOC                              24994 non-null  float64\n",
            " 25  DIT                                24994 non-null  float64\n",
            " 26  NOA                                24994 non-null  float64\n",
            " 27  NOC                                24994 non-null  float64\n",
            " 28  NOD                                24994 non-null  float64\n",
            " 29  NOP                                24994 non-null  float64\n",
            " 30  LLOC                               24994 non-null  float64\n",
            " 31  LOC                                24994 non-null  float64\n",
            " 32  NA                                 24994 non-null  float64\n",
            " 33  NG                                 24994 non-null  float64\n",
            " 34  NLA                                24994 non-null  float64\n",
            " 35  NLG                                24994 non-null  float64\n",
            " 36  NLM                                24994 non-null  float64\n",
            " 37  NLPA                               24994 non-null  float64\n",
            " 38  NLPM                               24994 non-null  float64\n",
            " 39  NLS                                24994 non-null  float64\n",
            " 40  NM                                 24994 non-null  float64\n",
            " 41  NOS                                24994 non-null  float64\n",
            " 42  NPA                                24994 non-null  float64\n",
            " 43  NPM                                24994 non-null  float64\n",
            " 44  NS                                 24994 non-null  float64\n",
            " 45  TLLOC                              24994 non-null  float64\n",
            " 46  TLOC                               24994 non-null  float64\n",
            " 47  TNA                                24994 non-null  float64\n",
            " 48  TNG                                24994 non-null  float64\n",
            " 49  TNLA                               24994 non-null  float64\n",
            " 50  TNLG                               24994 non-null  float64\n",
            " 51  TNLM                               24994 non-null  float64\n",
            " 52  TNLPA                              24994 non-null  float64\n",
            " 53  TNLPM                              24994 non-null  float64\n",
            " 54  TNLS                               24994 non-null  float64\n",
            " 55  TNM                                24994 non-null  float64\n",
            " 56  TNOS                               24994 non-null  float64\n",
            " 57  TNPA                               24994 non-null  float64\n",
            " 58  TNPM                               24994 non-null  float64\n",
            " 59  TNS                                24994 non-null  float64\n",
            " 60  WarningBlocker                     24994 non-null  float64\n",
            " 61  WarningCritical                    24994 non-null  float64\n",
            " 62  WarningMajor                       24994 non-null  float64\n",
            " 63  WarningMinor                       24994 non-null  float64\n",
            " 64  Basic Rules                        24994 non-null  float64\n",
            " 65  Brace Rules                        24994 non-null  float64\n",
            " 66  Clone Implementation Rules         24994 non-null  float64\n",
            " 67  Controversial Rules                24994 non-null  float64\n",
            " 68  Design Rules                       24994 non-null  float64\n",
            " 69  Empty Code Rules                   24994 non-null  float64\n",
            " 70  Finalizer Rules                    24994 non-null  float64\n",
            " 71  Import Statement Rules             24994 non-null  float64\n",
            " 72  J2EE Rules                         24994 non-null  float64\n",
            " 73  JUnit Rules                        24994 non-null  float64\n",
            " 74  Jakarta Commons Logging Rules      24994 non-null  float64\n",
            " 75  Java Logging Rules                 24994 non-null  float64\n",
            " 76  JavaBean Rules                     24994 non-null  float64\n",
            " 77  Migration Rules                    24994 non-null  float64\n",
            " 78  Naming Rules                       24994 non-null  float64\n",
            " 79  Optimization Rules                 24994 non-null  float64\n",
            " 80  Security Code Guideline Rules      24994 non-null  float64\n",
            " 81  Strict Exception Rules             24994 non-null  float64\n",
            " 82  String and StringBuffer Rules      24994 non-null  float64\n",
            " 83  Type Resolution Rules              24994 non-null  float64\n",
            " 84  Unnecessary and Unused Code Rules  24994 non-null  float64\n",
            " 85  Number of Bugs                     24994 non-null  float64\n",
            "dtypes: float64(86)\n",
            "memory usage: 16.4 MB\n",
            "+--------------+-----------------+-----------+-----------+--------------------------------------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state | n_estimatorsint | criterion | max_depth |                 confusion_matrix                 | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+-----------------+-----------+-----------+--------------------------------------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |                 |           |           | [[2006  883  193   17    1    3    0    0    0]  |        0.42       |      0.21      |      0.43      |     1655    |\n",
            "|              |                 |           |           |  [1186  469  262   37    2    2    2    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 289  248  142  120    1    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  38   49  132   42   15    1    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   5    3    6   26   14    5    2    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   3    3    0    4   10    7    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   3    3    0    2    0    3    2    1    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   0    0    0    0    0    0    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   1    0    0    0    0    0    3    1    0]] |                   |                |                |             |\n",
            "|      80      |        10       |    gini   |     1     | [[3103    0    0    0    0    0    0    0    0]  |        0.33       |      0.07      |      0.50      |     1960    |\n",
            "|              |                 |           |           |  [1960    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 800    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 277    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  61    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  28    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  14    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   1    0    0    0    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   5    0    0    0    0    0    0    0    0]] |                   |                |                |             |\n",
            "|      50      |       100       |  entropy  |     10    | [[2945  142   12    3    0    1    0    0    0]  |        0.39       |      0.17      |      0.50      |     1907    |\n",
            "|              |                 |           |           |  [1762  145   44    6    0    2    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 632  116   33   19    0    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 198   40   29    8    1    1    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  33    9    3    4    7    4    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  12    3    0    1    7    4    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   5    1    0    1    1    3    3    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   0    0    0    0    0    0    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   2    0    0    0    0    0    2    1    0]] |                   |                |                |             |\n",
            "|      60      |        50       |  entropy  |     20    | [[2083  837  164   15    2    2    0    0    0]  |        0.42       |      0.22      |      0.44      |     1687    |\n",
            "|              |                 |           |           |  [1240  447  234   34    2    2    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 305  242  130  122    1    0    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  43   49  127   38   18    2    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   4    3    6   27   13    7    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   4    2    0    3   11    7    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   2    4    1    1    1    2    3    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   0    0    0    0    0    0    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   1    0    0    0    0    0    3    1    0]] |                   |                |                |             |\n",
            "|      40      |        1        |    gini   |     30    | [[1748  939  322   78   13    3    0    0    0]  |        0.41       |      0.19      |      0.41      |     1567    |\n",
            "|              |                 |           |           |  [ 974  593  300   80    7    2    4    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [ 266  265  158  100    8    3    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [  50   61  104   45   14    3    0    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   5   10    6   24   12    3    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   2    4    0    4   11    4    3    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   2    3    2    1    1    2    2    1    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   0    0    0    0    0    0    1    0    0]  |                   |                |                |             |\n",
            "|              |                 |           |           |  [   1    1    0    0    0    0    1    2    0]] |                   |                |                |             |\n",
            "+--------------+-----------------+-----------+-----------+--------------------------------------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression"
      ],
      "metadata": {
        "id": "H4UNU-EDZqR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "'''Create logistic regression classifier'''  \n",
        "model1 = LogisticRegression()\n",
        "model2 = LogisticRegression(solver='sag', penalty='l2',n_jobs=-1, random_state=10)\n",
        "model3 = LogisticRegression(solver='saga', penalty='l2',n_jobs=-1, random_state=20)\n",
        "model4 = LogisticRegression(solver='liblinear', penalty='l1',n_jobs=-1, random_state=0)\n",
        "model5 = LogisticRegression(solver='liblinear', penalty='l2',n_jobs=-1, random_state=90)\n",
        "model6 = LogisticRegression(solver='lbfgs', penalty='l2',n_jobs=-1, random_state=50)\n",
        "model7 = LogisticRegression(solver='newton-cg', penalty='l2',n_jobs=-1, random_state=90)\n",
        "\n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "model6.fit(train[features], y)\n",
        "model7.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "preds6 = bugs.values[model6.predict(test[features])]\n",
        "preds7 = bugs.values[model7.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "cr6 = confusion_matrix(actual_classes, preds6)\n",
        "cr7 = confusion_matrix(actual_classes, preds7)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "tn6 = cr6[1,0]\n",
        "fn6 = cr6[1,1]\n",
        "tn7 = cr7[1,0]\n",
        "fn7 = cr7[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "bugs_number6 = tn6 + fn6\n",
        "bugs_number7 = tn7 + fn7\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "f1_weighted6 = f1_score(actual_classes, preds6, average = 'weighted')\n",
        "f1_weighted7 = f1_score(actual_classes, preds7, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "f1_macro6 = f1_score(actual_classes, preds6, average = 'macro')\n",
        "f1_macro7 = f1_score(actual_classes, preds7, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "f1_micro6 = f1_score(actual_classes, preds6, average = 'micro')\n",
        "f1_micro7 = f1_score(actual_classes, preds7, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "f1_score_weighted6 = \"%.2f\"%round(f1_weighted6, 2)\n",
        "f1_score_weighted7 = \"%.2f\"%round(f1_weighted7, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "f1_score_macro6 = \"%.2f\"%round(f1_macro6, 2)\n",
        "f1_score_macro7 = \"%.2f\"%round(f1_macro7, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "f1_score_micro6 = \"%.2f\"%round(f1_micro6, 2)\n",
        "f1_score_micro7 = \"%.2f\"%round(f1_micro7, 2)\n",
        "\n",
        "print('Logistic regression')\n",
        "head = PrettyTable(['random_state', 'solver', 'penalty', 'n_jobs', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['10', 'sag', 'l2', '-1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['20', 'saga', 'l2', '-1', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['0', 'liblinear', 'l1', '-1', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['90', 'liblinear', 'l2', '-1', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "head.add_row(['50', 'lbfgs', 'l2', '-1', cr6, f1_score_weighted6, f1_score_macro6, f1_score_micro6, bugs_number6]) \n",
        "head.add_row(['90', 'newton-cg', 'l2', '-1', cr7, f1_score_weighted7, f1_score_macro7, f1_score_micro7, bugs_number7]) \n",
        "print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gCdhzlXZrFC",
        "outputId": "d8706a4d-961b-48be-e8e9-ff06393255d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| random_state |   solver  | penalty | n_jobs | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|              |           |         |        |    [[128   8]    |        0.83       |      0.46      |      0.85      |      14     |\n",
            "|              |           |         |        |    [ 14   0]]    |                   |                |                |             |\n",
            "|      10      |    sag    |    l2   |   -1   |    [[135   1]    |        0.86       |      0.47      |      0.90      |      14     |\n",
            "|              |           |         |        |    [ 14   0]]    |                   |                |                |             |\n",
            "|      20      |    saga   |    l2   |   -1   |    [[135   1]    |        0.86       |      0.47      |      0.90      |      14     |\n",
            "|              |           |         |        |    [ 14   0]]    |                   |                |                |             |\n",
            "|      0       | liblinear |    l1   |   -1   |    [[130   6]    |        0.85       |      0.51      |      0.87      |      14     |\n",
            "|              |           |         |        |    [ 13   1]]    |                   |                |                |             |\n",
            "|      90      | liblinear |    l2   |   -1   |    [[128   8]    |        0.83       |      0.46      |      0.85      |      14     |\n",
            "|              |           |         |        |    [ 14   0]]    |                   |                |                |             |\n",
            "|      50      |   lbfgs   |    l2   |   -1   |    [[128   8]    |        0.83       |      0.46      |      0.85      |      14     |\n",
            "|              |           |         |        |    [ 14   0]]    |                   |                |                |             |\n",
            "|      90      | newton-cg |    l2   |   -1   |    [[128   8]    |        0.85       |      0.51      |      0.86      |      14     |\n",
            "|              |           |         |        |    [ 13   1]]    |                   |                |                |             |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "naive bayes"
      ],
      "metadata": {
        "id": "uSdClp5WaK2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# naive bayes\n",
        "'''Create naive bayes classifier'''\n",
        "model1 = GaussianNB()\n",
        "model2 = GaussianNB(var_smoothing = 1e-11)\n",
        "model3 = GaussianNB(var_smoothing = 1e-09)\n",
        "model4 = GaussianNB(var_smoothing = 1e-10)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "\n",
        "print('Naive bayes')\n",
        "head = PrettyTable(['var_smoothing', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['1e-11', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['1e-9', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['1e-10', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eit6SIcTaLKR",
        "outputId": "6a670848-2aa8-4231-bc96-52e089020151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive bayes\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n",
            "| var_smoothing | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro | bugs-number |\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n",
            "|               |     [[85 51]     |        0.70       |      0.50      |      0.63      |      14     |\n",
            "|               |     [ 5  9]]     |                   |                |                |             |\n",
            "|     1e-11     |     [[58 78]     |        0.56       |      0.41      |      0.47      |      14     |\n",
            "|               |     [ 2 12]]     |                   |                |                |             |\n",
            "|      1e-9     |     [[85 51]     |        0.70       |      0.50      |      0.63      |      14     |\n",
            "|               |     [ 5  9]]     |                   |                |                |             |\n",
            "|     1e-10     |     [[66 70]     |        0.60       |      0.43      |      0.51      |      14     |\n",
            "|               |     [ 4 10]]     |                   |                |                |             |\n",
            "+---------------+------------------+-------------------+----------------+----------------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Layer Perceptron Neural Network"
      ],
      "metadata": {
        "id": "GRlMzgkrabH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Layer Perceptron Neural Network\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model1 = MLPClassifier()\n",
        "model2 = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(5, 2), activation = 'tanh', random_state=10)\n",
        "model3 = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(150, 100, 50), activation = 'logistic',random_state=1)\n",
        "model4 = MLPClassifier(solver='adam', alpha=0.05, hidden_layer_sizes=(100, 50, 30), activation = 'relu', random_state=90)\n",
        "model5 = MLPClassifier(solver='lbfgs', alpha=0.0001, hidden_layer_sizes=(120, 80, 40), activation = 'identity', random_state=40)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "print('Multi layer perceptron neural network')\n",
        "head = PrettyTable(['random_state', 'activation', 'solver', 'hidden_layer_sizestuple', 'alpha', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['10', 'tanh', 'lbfgs', '(5, 2)', '0.01', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['1', 'logistic', 'sgd', '(150, 100, 50)', 'le-5', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['90', 'relu', 'adam', '(100, 50, 30)', '0.05', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['40', 'identity', 'lbfgs', '(120, 80, 40)', '0.0001', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "B6xw-eOJabcu",
        "outputId": "5805ee2f-fe9d-4e3c-f493-51f8d36b09b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-92ab74539466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Multi-Layer Perceptron Neural Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m'''Create Artificial Neural Network classifier'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machine"
      ],
      "metadata": {
        "id": "PUj2zqafawiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Support vector machine\n",
        "'''Create Artificial Neural Network classifier'''\n",
        "model1 = SVC()\n",
        "model2 = SVC(kernel='sigmoid', C=100, gamma=1, random_state=85)\n",
        "model3 = SVC(kernel='poly', C=10, gamma=0.1, random_state=12)\n",
        "model4 = SVC(kernel='rbf', C=0.1, gamma=0.01, random_state=15)\n",
        "model5 = SVC(kernel='linear', C=1, gamma=0.001, random_state=74)\n",
        "  \n",
        "'''Train and test'''\n",
        "model1.fit(train[features], y)\n",
        "model2.fit(train[features], y)\n",
        "model3.fit(train[features], y)\n",
        "model4.fit(train[features], y)\n",
        "model5.fit(train[features], y)\n",
        "\n",
        "preds1 = bugs.values[model1.predict(test[features])]\n",
        "preds2 = bugs.values[model2.predict(test[features])]\n",
        "preds3 = bugs.values[model3.predict(test[features])]\n",
        "preds4 = bugs.values[model4.predict(test[features])]\n",
        "preds5 = bugs.values[model5.predict(test[features])]\n",
        "\n",
        "cr1 = confusion_matrix(actual_classes, preds1)\n",
        "cr2 = confusion_matrix(actual_classes, preds2)\n",
        "cr3 = confusion_matrix(actual_classes, preds3)\n",
        "cr4 = confusion_matrix(actual_classes, preds4)\n",
        "cr5 = confusion_matrix(actual_classes, preds5)\n",
        "\n",
        "tn1 = cr1[1,0]\n",
        "fn1 = cr1[1,1]\n",
        "tn2 = cr2[1,0]\n",
        "fn2 = cr2[1,1]\n",
        "tn3 = cr3[1,0]\n",
        "fn3 = cr3[1,1]\n",
        "tn4 = cr4[1,0]\n",
        "fn4 = cr4[1,1]\n",
        "tn5 = cr5[1,0]\n",
        "fn5 = cr5[1,1]\n",
        "\n",
        "bugs_number1 = tn1 + fn1\n",
        "bugs_number2 = tn2 + fn2\n",
        "bugs_number3 = tn3 + fn3\n",
        "bugs_number4 = tn4 + fn4\n",
        "bugs_number5 = tn5 + fn5\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_weighted1 = f1_score(actual_classes, preds1, average = 'weighted')\n",
        "f1_weighted2 = f1_score(actual_classes, preds2, average = 'weighted')\n",
        "f1_weighted3 = f1_score(actual_classes, preds3, average = 'weighted')\n",
        "f1_weighted4 = f1_score(actual_classes, preds4, average = 'weighted')\n",
        "f1_weighted5 = f1_score(actual_classes, preds5, average = 'weighted')\n",
        "\n",
        "f1_macro1 = f1_score(actual_classes, preds1, average = 'macro')\n",
        "f1_macro2 = f1_score(actual_classes, preds2, average = 'macro')\n",
        "f1_macro3 = f1_score(actual_classes, preds3, average = 'macro')\n",
        "f1_macro4 = f1_score(actual_classes, preds4, average = 'macro')\n",
        "f1_macro5 = f1_score(actual_classes, preds5, average = 'macro')\n",
        "\n",
        "f1_micro1 = f1_score(actual_classes, preds1, average = 'micro')\n",
        "f1_micro2 = f1_score(actual_classes, preds2, average = 'micro')\n",
        "f1_micro3 = f1_score(actual_classes, preds3, average = 'micro')\n",
        "f1_micro4 = f1_score(actual_classes, preds4, average = 'micro')\n",
        "f1_micro5 = f1_score(actual_classes, preds5, average = 'micro')\n",
        "\n",
        "f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "print('Support vector machine')\n",
        "head = PrettyTable(['random_state', 'c', 'gamma', 'kernel', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1, bugs_number1]) \n",
        "head.add_row(['85', '100', '1', 'sigmoid', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2, bugs_number2]) \n",
        "head.add_row(['12', '10', '0.1', 'poly', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3, bugs_number3]) \n",
        "head.add_row(['15', '0.01', '0.01', 'rbf', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4, bugs_number4]) \n",
        "head.add_row(['74', '1', '0.001', 'linear', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5, bugs_number5]) \n",
        "print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "PleHBPwRawvv",
        "outputId": "a480b76b-3b76-47b3-ac3a-67b54d4d22ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-38c2fa1ea151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Support vector machine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m'''Create Artificial Neural Network classifier'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision tree"
      ],
      "metadata": {
        "id": "3xYWfJCxbARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "print('Decision tree')\n",
        "head = PrettyTable(['random_state', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro', 'bugs-number']) \n",
        "max_depth_range = list(range(1, 15))\n",
        "for depth in max_depth_range:\n",
        "  '''Create decision tree classifier'''    \n",
        "  model = tree.DecisionTreeClassifier(max_depth = depth,  random_state = 90)\n",
        "  \n",
        "  '''Train and test'''\n",
        "  model.fit(train[features], y)\n",
        "  preds = bugs.values[model.predict(test[features])]\n",
        "\n",
        "  cr = confusion_matrix(actual_classes, preds)\n",
        "  tn = cr[1,0]\n",
        "  fn = cr[1,1]\n",
        "  bugs_number = tn + fn\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  f1_weighted = f1_score(actual_classes, preds, average = 'weighted')\n",
        "  f1_macro = f1_score(actual_classes, preds, average = 'macro')\n",
        "  f1_micro = f1_score(actual_classes, preds, average = 'micro')\n",
        "\n",
        "  f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "  f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "  f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "\n",
        "  head.add_row(['90', depth, cr, f1_score_weighted, f1_score_macro, f1_score_micro, bugs_number]) \n",
        "print(head)"
      ],
      "metadata": {
        "id": "JLoDYAa2bAzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
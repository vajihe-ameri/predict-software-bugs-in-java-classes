{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0OlJcE4MC5/h2LX7UK+9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vajihe-ameri/predict-software-bugs-in-java-classes/blob/main/tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "H8Cz6wdlnY4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn pandas\n",
        "!pip install prettytable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7moBUzj9nZnR",
        "outputId": "f04eec6d-8cf7-43f4-c4a4-59bb3badee28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=3265d86e8d331a2c28baabae4f499e3bb95de720da9f607dd202149957b390e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset"
      ],
      "metadata": {
        "id": "_0ENIcE_nbos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive \n",
        "drive = drive.mount('/content/drive') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUvJN9yenfMB",
        "outputId": "b7cc8837-f4ce-4974-fc40-e4a93cc9d43f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call algorithms from sklearntrain_featurestrain_fea"
      ],
      "metadata": {
        "id": "AbjoU_t7Y8D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project => {project}')\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "\n",
        "  df = pd.read_csv(_file)\n",
        "  print('information of file:', df.describe(include=\"all\"))\n",
        "  print('-------------------------------------------------------------------------------')\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "  df = pd.read_csv(_file, usecols = cols)\n",
        "  print('delete data NAN:',df.describe(include=\"all\"))\n",
        "  print('-------------------------------------------------------------------------------')\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  print('delete cols of string:',df.describe(include=\"all\"))\n",
        "  print('-------------------------------------------------------------------------------')\n",
        "  df = df.T.drop_duplicates().T\n",
        "  print('delete cols by same data:',df.describe(include=\"all\"))\n",
        "  print('-------------------------------------------------------------------------------')\n",
        "  df = (df-df.mean())/df.std()\n",
        "  print('data normalize:',df.describe(include=\"all\"))\n",
        "  print('-------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "e6c75lOWY9cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a37ac10-60db-4c58-e121-382f6caf30a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project => oryx\n",
            "information of file:                                             Hash  \\\n",
            "count                                        598   \n",
            "unique                                        87   \n",
            "top     d16f89b25fc5e12f94af6432274c66e0394c1743   \n",
            "freq                                          45   \n",
            "mean                                         NaN   \n",
            "std                                          NaN   \n",
            "min                                          NaN   \n",
            "25%                                          NaN   \n",
            "50%                                          NaN   \n",
            "75%                                          NaN   \n",
            "max                                          NaN   \n",
            "\n",
            "                                           LongName          CC         CCL  \\\n",
            "count                                           598  598.000000  598.000000   \n",
            "unique                                          194         NaN         NaN   \n",
            "top     com.cloudera.oryx.lambda.AbstractSparkLayer         NaN         NaN   \n",
            "freq                                             11         NaN         NaN   \n",
            "mean                                            NaN    0.083616    0.411371   \n",
            "std                                             NaN    0.175586    1.001509   \n",
            "min                                             NaN    0.000000    0.000000   \n",
            "25%                                             NaN    0.000000    0.000000   \n",
            "50%                                             NaN    0.000000    0.000000   \n",
            "75%                                             NaN    0.000000    0.000000   \n",
            "max                                             NaN    1.000000    8.000000   \n",
            "\n",
            "               CCO          CI         CLC        CLLC         LDC  \\\n",
            "count   598.000000  598.000000  598.000000  598.000000  598.000000   \n",
            "unique         NaN         NaN         NaN         NaN         NaN   \n",
            "top            NaN         NaN         NaN         NaN         NaN   \n",
            "freq           NaN         NaN         NaN         NaN         NaN   \n",
            "mean      0.963211    0.444816    0.076221    0.078048    7.473244   \n",
            "std       2.711472    1.057540    0.160963    0.164450   19.164153   \n",
            "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "50%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "75%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "max      22.000000    8.000000    1.000000    1.000000  150.000000   \n",
            "\n",
            "              LLDC  ...  Migration15 Rules  Naming Rules  Optimization Rules  \\\n",
            "count   598.000000  ...              598.0    598.000000          598.000000   \n",
            "unique         NaN  ...                NaN           NaN                 NaN   \n",
            "top            NaN  ...                NaN           NaN                 NaN   \n",
            "freq           NaN  ...                NaN           NaN                 NaN   \n",
            "mean      6.297659  ...                0.0      0.769231            0.025084   \n",
            "std      16.302573  ...                0.0      1.448244            0.156510   \n",
            "min       0.000000  ...                0.0      0.000000            0.000000   \n",
            "25%       0.000000  ...                0.0      0.000000            0.000000   \n",
            "50%       0.000000  ...                0.0      0.000000            0.000000   \n",
            "75%       0.000000  ...                0.0      1.000000            0.000000   \n",
            "max     126.000000  ...                0.0     11.000000            1.000000   \n",
            "\n",
            "        Security Code Guideline Rules  Strict Exception Rules  \\\n",
            "count                      598.000000              598.000000   \n",
            "unique                            NaN                     NaN   \n",
            "top                               NaN                     NaN   \n",
            "freq                              NaN                     NaN   \n",
            "mean                         0.041806                0.023411   \n",
            "std                          0.283419                0.172052   \n",
            "min                          0.000000                0.000000   \n",
            "25%                          0.000000                0.000000   \n",
            "50%                          0.000000                0.000000   \n",
            "75%                          0.000000                0.000000   \n",
            "max                          4.000000                2.000000   \n",
            "\n",
            "        String and StringBuffer Rules  Type Resolution Rules  \\\n",
            "count                      598.000000             598.000000   \n",
            "unique                            NaN                    NaN   \n",
            "top                               NaN                    NaN   \n",
            "freq                              NaN                    NaN   \n",
            "mean                         0.108696               0.237458   \n",
            "std                          0.561069               0.570464   \n",
            "min                          0.000000               0.000000   \n",
            "25%                          0.000000               0.000000   \n",
            "50%                          0.000000               0.000000   \n",
            "75%                          0.000000               0.000000   \n",
            "max                          5.000000               4.000000   \n",
            "\n",
            "        Unnecessary and Unused Code Rules  Vulnerability Rules  Number of Bugs  \n",
            "count                          598.000000                598.0      598.000000  \n",
            "unique                                NaN                  NaN             NaN  \n",
            "top                                   NaN                  NaN             NaN  \n",
            "freq                                  NaN                  NaN             NaN  \n",
            "mean                             0.307692                  0.0        0.096990  \n",
            "std                              1.954844                  0.0        0.301794  \n",
            "min                              0.000000                  0.0        0.000000  \n",
            "25%                              0.000000                  0.0        0.000000  \n",
            "50%                              0.000000                  0.0        0.000000  \n",
            "75%                              0.000000                  0.0        0.000000  \n",
            "max                             20.000000                  0.0        2.000000  \n",
            "\n",
            "[11 rows x 98 columns]\n",
            "-------------------------------------------------------------------------------\n",
            "delete data NAN:                                             Hash  \\\n",
            "count                                        598   \n",
            "unique                                        87   \n",
            "top     d16f89b25fc5e12f94af6432274c66e0394c1743   \n",
            "freq                                          45   \n",
            "mean                                         NaN   \n",
            "std                                          NaN   \n",
            "min                                          NaN   \n",
            "25%                                          NaN   \n",
            "50%                                          NaN   \n",
            "75%                                          NaN   \n",
            "max                                          NaN   \n",
            "\n",
            "                                           LongName          CC         CCL  \\\n",
            "count                                           598  598.000000  598.000000   \n",
            "unique                                          194         NaN         NaN   \n",
            "top     com.cloudera.oryx.lambda.AbstractSparkLayer         NaN         NaN   \n",
            "freq                                             11         NaN         NaN   \n",
            "mean                                            NaN    0.083616    0.411371   \n",
            "std                                             NaN    0.175586    1.001509   \n",
            "min                                             NaN    0.000000    0.000000   \n",
            "25%                                             NaN    0.000000    0.000000   \n",
            "50%                                             NaN    0.000000    0.000000   \n",
            "75%                                             NaN    0.000000    0.000000   \n",
            "max                                             NaN    1.000000    8.000000   \n",
            "\n",
            "               CCO          CI         CLC        CLLC         LDC  \\\n",
            "count   598.000000  598.000000  598.000000  598.000000  598.000000   \n",
            "unique         NaN         NaN         NaN         NaN         NaN   \n",
            "top            NaN         NaN         NaN         NaN         NaN   \n",
            "freq           NaN         NaN         NaN         NaN         NaN   \n",
            "mean      0.963211    0.444816    0.076221    0.078048    7.473244   \n",
            "std       2.711472    1.057540    0.160963    0.164450   19.164153   \n",
            "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "50%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "75%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "max      22.000000    8.000000    1.000000    1.000000  150.000000   \n",
            "\n",
            "              LLDC  ...  Migration15 Rules  Naming Rules  Optimization Rules  \\\n",
            "count   598.000000  ...              598.0    598.000000          598.000000   \n",
            "unique         NaN  ...                NaN           NaN                 NaN   \n",
            "top            NaN  ...                NaN           NaN                 NaN   \n",
            "freq           NaN  ...                NaN           NaN                 NaN   \n",
            "mean      6.297659  ...                0.0      0.769231            0.025084   \n",
            "std      16.302573  ...                0.0      1.448244            0.156510   \n",
            "min       0.000000  ...                0.0      0.000000            0.000000   \n",
            "25%       0.000000  ...                0.0      0.000000            0.000000   \n",
            "50%       0.000000  ...                0.0      0.000000            0.000000   \n",
            "75%       0.000000  ...                0.0      1.000000            0.000000   \n",
            "max     126.000000  ...                0.0     11.000000            1.000000   \n",
            "\n",
            "        Security Code Guideline Rules  Strict Exception Rules  \\\n",
            "count                      598.000000              598.000000   \n",
            "unique                            NaN                     NaN   \n",
            "top                               NaN                     NaN   \n",
            "freq                              NaN                     NaN   \n",
            "mean                         0.041806                0.023411   \n",
            "std                          0.283419                0.172052   \n",
            "min                          0.000000                0.000000   \n",
            "25%                          0.000000                0.000000   \n",
            "50%                          0.000000                0.000000   \n",
            "75%                          0.000000                0.000000   \n",
            "max                          4.000000                2.000000   \n",
            "\n",
            "        String and StringBuffer Rules  Type Resolution Rules  \\\n",
            "count                      598.000000             598.000000   \n",
            "unique                            NaN                    NaN   \n",
            "top                               NaN                    NaN   \n",
            "freq                              NaN                    NaN   \n",
            "mean                         0.108696               0.237458   \n",
            "std                          0.561069               0.570464   \n",
            "min                          0.000000               0.000000   \n",
            "25%                          0.000000               0.000000   \n",
            "50%                          0.000000               0.000000   \n",
            "75%                          0.000000               0.000000   \n",
            "max                          5.000000               4.000000   \n",
            "\n",
            "        Unnecessary and Unused Code Rules  Vulnerability Rules  Number of Bugs  \n",
            "count                          598.000000                598.0      598.000000  \n",
            "unique                                NaN                  NaN             NaN  \n",
            "top                                   NaN                  NaN             NaN  \n",
            "freq                                  NaN                  NaN             NaN  \n",
            "mean                             0.307692                  0.0        0.096990  \n",
            "std                              1.954844                  0.0        0.301794  \n",
            "min                              0.000000                  0.0        0.000000  \n",
            "25%                              0.000000                  0.0        0.000000  \n",
            "50%                              0.000000                  0.0        0.000000  \n",
            "75%                              0.000000                  0.0        0.000000  \n",
            "max                             20.000000                  0.0        2.000000  \n",
            "\n",
            "[11 rows x 98 columns]\n",
            "-------------------------------------------------------------------------------\n",
            "delete cols of string:                CC         CCL         CCO          CI         CLC        CLLC  \\\n",
            "count  598.000000  598.000000  598.000000  598.000000  598.000000  598.000000   \n",
            "mean     0.083616    0.411371    0.963211    0.444816    0.076221    0.078048   \n",
            "std      0.175586    1.001509    2.711472    1.057540    0.160963    0.164450   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "max      1.000000    8.000000   22.000000    8.000000    1.000000    1.000000   \n",
            "\n",
            "              LDC        LLDC       LCOM5          NL  ...  Migration15 Rules  \\\n",
            "count  598.000000  598.000000  598.000000  598.000000  ...              598.0   \n",
            "mean     7.473244    6.297659    1.642140    1.809365  ...                0.0   \n",
            "std     19.164153   16.302573    1.567797    1.277474  ...                0.0   \n",
            "min      0.000000    0.000000    0.000000    0.000000  ...                0.0   \n",
            "25%      0.000000    0.000000    1.000000    1.000000  ...                0.0   \n",
            "50%      0.000000    0.000000    1.000000    2.000000  ...                0.0   \n",
            "75%      0.000000    0.000000    1.750000    3.000000  ...                0.0   \n",
            "max    150.000000  126.000000   11.000000    5.000000  ...                0.0   \n",
            "\n",
            "       Naming Rules  Optimization Rules  Security Code Guideline Rules  \\\n",
            "count    598.000000          598.000000                     598.000000   \n",
            "mean       0.769231            0.025084                       0.041806   \n",
            "std        1.448244            0.156510                       0.283419   \n",
            "min        0.000000            0.000000                       0.000000   \n",
            "25%        0.000000            0.000000                       0.000000   \n",
            "50%        0.000000            0.000000                       0.000000   \n",
            "75%        1.000000            0.000000                       0.000000   \n",
            "max       11.000000            1.000000                       4.000000   \n",
            "\n",
            "       Strict Exception Rules  String and StringBuffer Rules  \\\n",
            "count              598.000000                     598.000000   \n",
            "mean                 0.023411                       0.108696   \n",
            "std                  0.172052                       0.561069   \n",
            "min                  0.000000                       0.000000   \n",
            "25%                  0.000000                       0.000000   \n",
            "50%                  0.000000                       0.000000   \n",
            "75%                  0.000000                       0.000000   \n",
            "max                  2.000000                       5.000000   \n",
            "\n",
            "       Type Resolution Rules  Unnecessary and Unused Code Rules  \\\n",
            "count             598.000000                         598.000000   \n",
            "mean                0.237458                           0.307692   \n",
            "std                 0.570464                           1.954844   \n",
            "min                 0.000000                           0.000000   \n",
            "25%                 0.000000                           0.000000   \n",
            "50%                 0.000000                           0.000000   \n",
            "75%                 0.000000                           0.000000   \n",
            "max                 4.000000                          20.000000   \n",
            "\n",
            "       Vulnerability Rules  Number of Bugs  \n",
            "count                598.0      598.000000  \n",
            "mean                   0.0        0.096990  \n",
            "std                    0.0        0.301794  \n",
            "min                    0.0        0.000000  \n",
            "25%                    0.0        0.000000  \n",
            "50%                    0.0        0.000000  \n",
            "75%                    0.0        0.000000  \n",
            "max                    0.0        2.000000  \n",
            "\n",
            "[8 rows x 96 columns]\n",
            "-------------------------------------------------------------------------------\n",
            "delete cols by same data:                CC         CCL         CCO          CI         CLC        CLLC  \\\n",
            "count  598.000000  598.000000  598.000000  598.000000  598.000000  598.000000   \n",
            "mean     0.083616    0.411371    0.963211    0.444816    0.076221    0.078048   \n",
            "std      0.175586    1.001509    2.711472    1.057540    0.160963    0.164450   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "max      1.000000    8.000000   22.000000    8.000000    1.000000    1.000000   \n",
            "\n",
            "              LDC        LLDC       LCOM5          NL  ...  \\\n",
            "count  598.000000  598.000000  598.000000  598.000000  ...   \n",
            "mean     7.473244    6.297659    1.642140    1.809365  ...   \n",
            "std     19.164153   16.302573    1.567797    1.277474  ...   \n",
            "min      0.000000    0.000000    0.000000    0.000000  ...   \n",
            "25%      0.000000    0.000000    1.000000    1.000000  ...   \n",
            "50%      0.000000    0.000000    1.000000    2.000000  ...   \n",
            "75%      0.000000    0.000000    1.750000    3.000000  ...   \n",
            "max    150.000000  126.000000   11.000000    5.000000  ...   \n",
            "\n",
            "       Java Logging Rules  JavaBean Rules  Naming Rules  Optimization Rules  \\\n",
            "count          598.000000      598.000000    598.000000          598.000000   \n",
            "mean             0.001672        0.010033      0.769231            0.025084   \n",
            "std              0.040893        0.099747      1.448244            0.156510   \n",
            "min              0.000000        0.000000      0.000000            0.000000   \n",
            "25%              0.000000        0.000000      0.000000            0.000000   \n",
            "50%              0.000000        0.000000      0.000000            0.000000   \n",
            "75%              0.000000        0.000000      1.000000            0.000000   \n",
            "max              1.000000        1.000000     11.000000            1.000000   \n",
            "\n",
            "       Security Code Guideline Rules  Strict Exception Rules  \\\n",
            "count                     598.000000              598.000000   \n",
            "mean                        0.041806                0.023411   \n",
            "std                         0.283419                0.172052   \n",
            "min                         0.000000                0.000000   \n",
            "25%                         0.000000                0.000000   \n",
            "50%                         0.000000                0.000000   \n",
            "75%                         0.000000                0.000000   \n",
            "max                         4.000000                2.000000   \n",
            "\n",
            "       String and StringBuffer Rules  Type Resolution Rules  \\\n",
            "count                     598.000000             598.000000   \n",
            "mean                        0.108696               0.237458   \n",
            "std                         0.561069               0.570464   \n",
            "min                         0.000000               0.000000   \n",
            "25%                         0.000000               0.000000   \n",
            "50%                         0.000000               0.000000   \n",
            "75%                         0.000000               0.000000   \n",
            "max                         5.000000               4.000000   \n",
            "\n",
            "       Unnecessary and Unused Code Rules  Number of Bugs  \n",
            "count                         598.000000      598.000000  \n",
            "mean                            0.307692        0.096990  \n",
            "std                             1.954844        0.301794  \n",
            "min                             0.000000        0.000000  \n",
            "25%                             0.000000        0.000000  \n",
            "50%                             0.000000        0.000000  \n",
            "75%                             0.000000        0.000000  \n",
            "max                            20.000000        2.000000  \n",
            "\n",
            "[8 rows x 74 columns]\n",
            "-------------------------------------------------------------------------------\n",
            "data normalize:                  CC         CCL           CCO            CI           CLC  \\\n",
            "count  5.980000e+02  598.000000  5.980000e+02  5.980000e+02  5.980000e+02   \n",
            "mean  -9.505588e-17    0.000000 -4.752794e-17  7.129191e-17 -9.505588e-17   \n",
            "std    1.000000e+00    1.000000  1.000000e+00  1.000000e+00  1.000000e+00   \n",
            "min   -4.762116e-01   -0.410752 -3.552354e-01 -4.206141e-01 -4.735322e-01   \n",
            "25%   -4.762116e-01   -0.410752 -3.552354e-01 -4.206141e-01 -4.735322e-01   \n",
            "50%   -4.762116e-01   -0.410752 -3.552354e-01 -4.206141e-01 -4.735322e-01   \n",
            "75%   -4.762116e-01   -0.410752 -3.552354e-01 -4.206141e-01 -4.735322e-01   \n",
            "max    5.218992e+00    7.577197  7.758440e+00  7.144114e+00  5.739064e+00   \n",
            "\n",
            "               CLLC           LDC          LLDC       LCOM5            NL  \\\n",
            "count  5.980000e+02  5.980000e+02  5.980000e+02  598.000000  5.980000e+02   \n",
            "mean   1.901118e-16  4.752794e-17  4.752794e-17    0.000000  1.663478e-16   \n",
            "std    1.000000e+00  1.000000e+00  1.000000e+00    1.000000  1.000000e+00   \n",
            "min   -4.746021e-01 -3.899595e-01 -3.862985e-01   -1.047419 -1.416362e+00   \n",
            "25%   -4.746021e-01 -3.899595e-01 -3.862985e-01   -0.409581 -6.335665e-01   \n",
            "50%   -4.746021e-01 -3.899595e-01 -3.862985e-01   -0.409581  1.492285e-01   \n",
            "75%   -4.746021e-01 -3.899595e-01 -3.862985e-01    0.068797  9.320235e-01   \n",
            "max    5.606260e+00  7.437154e+00  7.342543e+00    5.968796  2.497613e+00   \n",
            "\n",
            "       ...  Java Logging Rules  JavaBean Rules  Naming Rules  \\\n",
            "count  ...        5.980000e+02      598.000000  5.980000e+02   \n",
            "mean   ...        2.970496e-17        0.000000 -4.752794e-17   \n",
            "std    ...        1.000000e+00        1.000000  1.000000e+00   \n",
            "min    ...       -4.089304e-02       -0.100589 -5.311473e-01   \n",
            "25%    ...       -4.089304e-02       -0.100589 -5.311473e-01   \n",
            "50%    ...       -4.089304e-02       -0.100589 -5.311473e-01   \n",
            "75%    ...       -4.089304e-02       -0.100589  1.593442e-01   \n",
            "max    ...        2.441315e+01        9.924801  7.064259e+00   \n",
            "\n",
            "       Optimization Rules  Security Code Guideline Rules  \\\n",
            "count        5.980000e+02                   5.980000e+02   \n",
            "mean         1.485248e-17                  -2.970496e-17   \n",
            "std          1.000000e+00                   1.000000e+00   \n",
            "min         -1.602684e-01                  -1.475060e-01   \n",
            "25%         -1.602684e-01                  -1.475060e-01   \n",
            "50%         -1.602684e-01                  -1.475060e-01   \n",
            "75%         -1.602684e-01                  -1.475060e-01   \n",
            "max          6.229099e+00                   1.396587e+01   \n",
            "\n",
            "       Strict Exception Rules  String and StringBuffer Rules  \\\n",
            "count            5.980000e+02                   5.980000e+02   \n",
            "mean             1.188199e-17                   5.940993e-18   \n",
            "std              1.000000e+00                   1.000000e+00   \n",
            "min             -1.360718e-01                  -1.937295e-01   \n",
            "25%             -1.360718e-01                  -1.937295e-01   \n",
            "50%             -1.360718e-01                  -1.937295e-01   \n",
            "75%             -1.360718e-01                  -1.937295e-01   \n",
            "max              1.148835e+01                   8.717827e+00   \n",
            "\n",
            "       Type Resolution Rules  Unnecessary and Unused Code Rules  \\\n",
            "count           5.980000e+02                       5.980000e+02   \n",
            "mean           -1.188199e-17                       4.752794e-17   \n",
            "std             1.000000e+00                       1.000000e+00   \n",
            "min            -4.162548e-01                      -1.573999e-01   \n",
            "25%            -4.162548e-01                      -1.573999e-01   \n",
            "50%            -4.162548e-01                      -1.573999e-01   \n",
            "75%            -4.162548e-01                      -1.573999e-01   \n",
            "max             6.595586e+00                       1.007360e+01   \n",
            "\n",
            "       Number of Bugs  \n",
            "count    5.980000e+02  \n",
            "mean    -3.861645e-17  \n",
            "std      1.000000e+00  \n",
            "min     -3.213779e-01  \n",
            "25%     -3.213779e-01  \n",
            "50%     -3.213779e-01  \n",
            "75%     -3.213779e-01  \n",
            "max      6.305656e+00  \n",
            "\n",
            "[8 rows x 74 columns]\n",
            "-------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest"
      ],
      "metadata": {
        "id": "i7g4skTHZSfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random forest')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "  \n",
        "  '''Create random forest classifier'''\n",
        "  model1 = RandomForestClassifier()\n",
        "  model2 = RandomForestClassifier(n_estimators=100, criterion = 'gini', max_depth = 1, random_state = 80)\n",
        "  model3 = RandomForestClassifier(n_estimators=90, criterion = 'entropy' , max_depth = 10, random_state = 50)\n",
        "  model4 = RandomForestClassifier(n_estimators=50, criterion = 'entropy', max_depth = 20, random_state = 60)\n",
        "  model5 = RandomForestClassifier(n_estimators=1, criterion = 'gini', max_depth = 30, random_state = 40)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train_features, train_target)\n",
        "  model2.fit(train_features, train_target)\n",
        "  model3.fit(train_features, train_target)\n",
        "  model4.fit(train_features, train_target)\n",
        "  model5.fit(train_features, train_target)\n",
        "\n",
        "  preds1 = model1.predict(test_features)\n",
        "  preds2 = model2.predict(test_features)\n",
        "  preds3 = model3.predict(test_features)\n",
        "  preds4 = model4.predict(test_features)\n",
        "  preds5 = model5.predict(test_features)\n",
        "\n",
        "  cr1 = confusion_matrix(test_target, preds1)\n",
        "  cr2 = confusion_matrix(test_target, preds2)\n",
        "  cr3 = confusion_matrix(test_target, preds3)\n",
        "  cr4 = confusion_matrix(test_target, preds4)\n",
        "  cr5 = confusion_matrix(test_target, preds5)\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(test_target, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(test_target, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(test_target, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(test_target, preds4, average = 'weighted')\n",
        "  f1_weighted5 = f1_score(test_target, preds5, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(test_target, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(test_target, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(test_target, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(test_target, preds4, average = 'macro')\n",
        "  f1_macro5 = f1_score(test_target, preds5, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(test_target, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(test_target, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(test_target, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(test_target, preds4, average = 'micro')\n",
        "  f1_micro5 = f1_score(test_target, preds5, average = 'micro')\n",
        "\n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "  f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "  f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "  f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "  head = PrettyTable(['random_state', 'n_estimatorsint', 'criterion', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1]) \n",
        "  head.add_row(['80', '10', 'gini', '1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2]) \n",
        "  head.add_row(['50', '100', 'entropy', '10', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3]) \n",
        "  head.add_row(['60', '50', 'entropy', '20', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4]) \n",
        "  head.add_row(['40', '1', 'gini', '30', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ9PWz8dZTSM",
        "outputId": "c0b2715e-a50d-4441-dcee-29b956211d51"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest\n",
            "Project: oryx\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+\n",
            "| random_state | n_estimatorsint | criterion | max_depth | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+\n",
            "|              |                 |           |           |  [[128   5   2]  |        0.85       |      0.37      |      0.87      |\n",
            "|              |                 |           |           |   [ 13   2   0]  |                   |                |                |\n",
            "|              |                 |           |           |  [  0   0   0]]  |                   |                |                |\n",
            "|      80      |        10       |    gini   |     1     |    [[135   0]    |        0.85       |      0.47      |      0.90      |\n",
            "|              |                 |           |           |    [ 15   0]]    |                   |                |                |\n",
            "|      50      |       100       |  entropy  |     10    |  [[130   3   2]  |        0.85       |      0.35      |      0.87      |\n",
            "|              |                 |           |           |   [ 14   1   0]  |                   |                |                |\n",
            "|              |                 |           |           |  [  0   0   0]]  |                   |                |                |\n",
            "|      60      |        50       |  entropy  |     20    |  [[128   5   2]  |        0.84       |      0.34      |      0.86      |\n",
            "|              |                 |           |           |   [ 14   1   0]  |                   |                |                |\n",
            "|              |                 |           |           |  [  0   0   0]]  |                   |                |                |\n",
            "|      40      |        1        |    gini   |     30    |    [[127   8]    |        0.85       |      0.54      |      0.86      |\n",
            "|              |                 |           |           |    [ 13   2]]    |                   |                |                |\n",
            "+--------------+-----------------+-----------+-----------+------------------+-------------------+----------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression"
      ],
      "metadata": {
        "id": "H4UNU-EDZqR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic regression')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "  \n",
        "  '''Create logistic regression classifier'''  \n",
        "  model1 = LogisticRegression()\n",
        "  model2 = LogisticRegression(solver='sag', penalty='l2',n_jobs=-1, random_state=10)\n",
        "  model3 = LogisticRegression(solver='saga', penalty='l2',n_jobs=-1, random_state=20)\n",
        "  model4 = LogisticRegression(solver='liblinear', penalty='l1',n_jobs=-1, random_state=0)\n",
        "  model5 = LogisticRegression(solver='liblinear', penalty='l2',n_jobs=-1, random_state=90)\n",
        "  model6 = LogisticRegression(solver='lbfgs', penalty='l2',n_jobs=-1, random_state=50)\n",
        "  model7 = LogisticRegression(solver='newton-cg', penalty='l2',n_jobs=-1, random_state=90)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train_features, train_target)\n",
        "  model2.fit(train_features, train_target)\n",
        "  model3.fit(train_features, train_target)\n",
        "  model4.fit(train_features, train_target)\n",
        "  model5.fit(train_features, train_target)\n",
        "  model6.fit(train_features, train_target)\n",
        "  model7.fit(train_features, train_target)\n",
        "\n",
        "  preds1 = model1.predict(test_features)\n",
        "  preds2 = model2.predict(test_features)\n",
        "  preds3 = model3.predict(test_features)\n",
        "  preds4 = model4.predict(test_features)\n",
        "  preds5 = model5.predict(test_features)\n",
        "  preds6 = model5.predict(test_features)\n",
        "  preds7 = model5.predict(test_features)\n",
        "\n",
        "  cr1 = confusion_matrix(test_target, preds1)\n",
        "  cr2 = confusion_matrix(test_target, preds2)\n",
        "  cr3 = confusion_matrix(test_target, preds3)\n",
        "  cr4 = confusion_matrix(test_target, preds4)\n",
        "  cr5 = confusion_matrix(test_target, preds5)\n",
        "  cr6 = confusion_matrix(test_target, preds5)\n",
        "  cr7 = confusion_matrix(test_target, preds5)\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(test_target, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(test_target, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(test_target, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(test_target, preds4, average = 'weighted')\n",
        "  f1_weighted5 = f1_score(test_target, preds5, average = 'weighted')\n",
        "  f1_weighted6 = f1_score(test_target, preds5, average = 'weighted')\n",
        "  f1_weighted7 = f1_score(test_target, preds5, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(test_target, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(test_target, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(test_target, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(test_target, preds4, average = 'macro')\n",
        "  f1_macro5 = f1_score(test_target, preds5, average = 'macro')\n",
        "  f1_macro6 = f1_score(test_target, preds5, average = 'macro')\n",
        "  f1_macro7 = f1_score(test_target, preds5, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(test_target, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(test_target, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(test_target, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(test_target, preds4, average = 'micro')\n",
        "  f1_micro5 = f1_score(test_target, preds5, average = 'micro')\n",
        "  f1_micro6 = f1_score(test_target, preds5, average = 'micro')\n",
        "  f1_micro7 = f1_score(test_target, preds5, average = 'micro')\n",
        " \n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "  f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "  f1_score_weighted6 = \"%.2f\"%round(f1_weighted6, 2)\n",
        "  f1_score_weighted7 = \"%.2f\"%round(f1_weighted7, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "  f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "  f1_score_macro6 = \"%.2f\"%round(f1_macro6, 2)\n",
        "  f1_score_macro7 = \"%.2f\"%round(f1_macro7, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "  f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "  f1_score_micro6 = \"%.2f\"%round(f1_micro6, 2)\n",
        "  f1_score_micro7 = \"%.2f\"%round(f1_micro7, 2)\n",
        "\n",
        "  head = PrettyTable(['random_state', 'solver', 'penalty', 'n_jobs', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1]) \n",
        "  head.add_row(['10', 'sag', 'l2', '-1', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2]) \n",
        "  head.add_row(['20', 'saga', 'l2', '-1', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3]) \n",
        "  head.add_row(['0', 'liblinear', 'l1', '-1', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4]) \n",
        "  head.add_row(['90', 'liblinear', 'l2', '-1', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5]) \n",
        "  head.add_row(['50', 'lbfgs', 'l2', '-1', cr6, f1_score_weighted6, f1_score_macro6, f1_score_micro6]) \n",
        "  head.add_row(['90', 'newton-cg', 'l2', '-1', cr7, f1_score_weighted7, f1_score_macro7, f1_score_micro7]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gCdhzlXZrFC",
        "outputId": "5f672cee-df81-4267-836a-967a83158903"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression\n",
            "Project: oryx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+\n",
            "| random_state |   solver  | penalty | n_jobs | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+\n",
            "|              |           |         |        |  [[128   4   1]  |        0.84       |      0.37      |      0.87      |\n",
            "|              |           |         |        |   [ 15   2   0]  |                   |                |                |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |\n",
            "|      10      |    sag    |    l2   |   -1   |    [[132   1]    |        0.83       |      0.47      |      0.88      |\n",
            "|              |           |         |        |    [ 17   0]]    |                   |                |                |\n",
            "|      20      |    saga   |    l2   |   -1   |    [[133   0]    |        0.83       |      0.47      |      0.89      |\n",
            "|              |           |         |        |    [ 17   0]]    |                   |                |                |\n",
            "|      0       | liblinear |    l1   |   -1   |  [[128   4   1]  |        0.86       |      0.42      |      0.88      |\n",
            "|              |           |         |        |   [ 13   4   0]  |                   |                |                |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |\n",
            "|      90      | liblinear |    l2   |   -1   |  [[128   4   1]  |        0.86       |      0.42      |      0.88      |\n",
            "|              |           |         |        |   [ 13   4   0]  |                   |                |                |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |\n",
            "|      50      |   lbfgs   |    l2   |   -1   |  [[128   4   1]  |        0.86       |      0.42      |      0.88      |\n",
            "|              |           |         |        |   [ 13   4   0]  |                   |                |                |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |\n",
            "|      90      | newton-cg |    l2   |   -1   |  [[128   4   1]  |        0.86       |      0.42      |      0.88      |\n",
            "|              |           |         |        |   [ 13   4   0]  |                   |                |                |\n",
            "|              |           |         |        |  [  0   0   0]]  |                   |                |                |\n",
            "+--------------+-----------+---------+--------+------------------+-------------------+----------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "naive bayes"
      ],
      "metadata": {
        "id": "uSdClp5WaK2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Naive bayes')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "  \n",
        "  '''Create random forest classifier'''\n",
        "  model1 = GaussianNB()\n",
        "  model2 = GaussianNB(var_smoothing = 1e-11)\n",
        "  model3 = GaussianNB(var_smoothing = 1e-09)\n",
        "  model4 = GaussianNB(var_smoothing = 1e-10)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train_features, train_target)\n",
        "  model2.fit(train_features, train_target)\n",
        "  model3.fit(train_features, train_target)\n",
        "  model4.fit(train_features, train_target)\n",
        "\n",
        "  preds1 = model1.predict(test_features)\n",
        "  preds2 = model2.predict(test_features)\n",
        "  preds3 = model3.predict(test_features)\n",
        "  preds4 = model4.predict(test_features)\n",
        "\n",
        "  cr1 = confusion_matrix(test_target, preds1)\n",
        "  cr2 = confusion_matrix(test_target, preds2)\n",
        "  cr3 = confusion_matrix(test_target, preds3)\n",
        "  cr4 = confusion_matrix(test_target, preds4)\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(test_target, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(test_target, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(test_target, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(test_target, preds4, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(test_target, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(test_target, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(test_target, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(test_target, preds4, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(test_target, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(test_target, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(test_target, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(test_target, preds4, average = 'micro')\n",
        "\n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "\n",
        "  head = PrettyTable(['var_smoothing', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  head.add_row(['', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1]) \n",
        "  head.add_row(['1e-11', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2]) \n",
        "  head.add_row(['1e-9', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3]) \n",
        "  head.add_row(['1e-10', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eit6SIcTaLKR",
        "outputId": "56a7fdf9-9525-4dc3-aa23-e055357c414d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive bayes\n",
            "Project: oryx\n",
            "+---------------+------------------+-------------------+----------------+----------------+\n",
            "| var_smoothing | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+---------------+------------------+-------------------+----------------+----------------+\n",
            "|               |     [[98 33]     |        0.78       |      0.62      |      0.74      |\n",
            "|               |     [ 6 13]]     |                   |                |                |\n",
            "|     1e-11     |     [[71 60]     |        0.65       |      0.53      |      0.59      |\n",
            "|               |     [ 2 17]]     |                   |                |                |\n",
            "|      1e-9     |     [[98 33]     |        0.78       |      0.62      |      0.74      |\n",
            "|               |     [ 6 13]]     |                   |                |                |\n",
            "|     1e-10     |     [[85 46]     |        0.72       |      0.56      |      0.66      |\n",
            "|               |     [ 5 14]]     |                   |                |                |\n",
            "+---------------+------------------+-------------------+----------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Layer Perceptron Neural Network"
      ],
      "metadata": {
        "id": "GRlMzgkrabH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Multi layer perceptron neural network')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "  \n",
        "  '''Create Artificial Neural Network classifier'''\n",
        "  model1 = MLPClassifier()\n",
        "  model2 = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(5, 2), activation = 'tanh', random_state=10)\n",
        "  model3 = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(150, 100, 50), activation = 'logistic',random_state=1)\n",
        "  model4 = MLPClassifier(solver='adam', alpha=0.05, hidden_layer_sizes=(100, 50, 30), activation = 'relu', random_state=90)\n",
        "  model5 = MLPClassifier(solver='lbfgs', alpha=0.0001, hidden_layer_sizes=(120, 80, 40), activation = 'identity', random_state=40)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train_features, train_target)\n",
        "  model2.fit(train_features, train_target)\n",
        "  model3.fit(train_features, train_target)\n",
        "  model4.fit(train_features, train_target)\n",
        "  model5.fit(train_features, train_target)\n",
        "\n",
        "  preds1 = model1.predict(test_features)\n",
        "  preds2 = model2.predict(test_features)\n",
        "  preds3 = model3.predict(test_features)\n",
        "  preds4 = model4.predict(test_features)\n",
        "  preds5 = model5.predict(test_features)\n",
        "\n",
        "  cr1 = confusion_matrix(test_target, preds1)\n",
        "  cr2 = confusion_matrix(test_target, preds2)\n",
        "  cr3 = confusion_matrix(test_target, preds3)\n",
        "  cr4 = confusion_matrix(test_target, preds4)\n",
        "  cr5 = confusion_matrix(test_target, preds5)\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(test_target, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(test_target, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(test_target, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(test_target, preds4, average = 'weighted')\n",
        "  f1_weighted5 = f1_score(test_target, preds5, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(test_target, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(test_target, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(test_target, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(test_target, preds4, average = 'macro')\n",
        "  f1_macro5 = f1_score(test_target, preds5, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(test_target, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(test_target, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(test_target, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(test_target, preds4, average = 'micro')\n",
        "  f1_micro5 = f1_score(test_target, preds5, average = 'micro')\n",
        "\n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "  f1_score_weighted5 = \"%.2f\"%round(f1_weighted5, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "  f1_score_macro5 = \"%.2f\"%round(f1_macro5, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "  f1_score_micro5 = \"%.2f\"%round(f1_micro5, 2)\n",
        "\n",
        "  head = PrettyTable(['random_state', 'activation', 'solver', 'hidden_layer_sizestuple', 'alpha', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  head.add_row(['', '', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1]) \n",
        "  head.add_row(['10', 'tanh', 'lbfgs', '(5, 2)', '0.01', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2]) \n",
        "  head.add_row(['1', 'logistic', 'sgd', '(150, 100, 50)', 'le-5', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3]) \n",
        "  head.add_row(['90', 'relu', 'adam', '(100, 50, 30)', '0.05', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4]) \n",
        "  head.add_row(['40', 'identity', 'lbfgs', '(120, 80, 40)', '0.0001', cr5, f1_score_weighted5, f1_score_macro5, f1_score_micro5]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6xw-eOJabcu",
        "outputId": "93b00810-071e-4969-ea62-25a1e0f82af0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi layer perceptron neural network\n",
            "Project: oryx\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+\n",
            "| random_state | activation | solver | hidden_layer_sizestuple | alpha  | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+\n",
            "|              |            |        |                         |        |  [[127   8   1]  |        0.85       |      0.36      |      0.86      |\n",
            "|              |            |        |                         |        |   [ 12   2   0]  |                   |                |                |\n",
            "|              |            |        |                         |        |  [  0   0   0]]  |                   |                |                |\n",
            "|      10      |    tanh    | lbfgs  |          (5, 2)         |  0.01  |    [[136   0]    |        0.86       |      0.48      |      0.91      |\n",
            "|              |            |        |                         |        |    [ 14   0]]    |                   |                |                |\n",
            "|      1       |  logistic  |  sgd   |      (150, 100, 50)     |  le-5  |    [[136   0]    |        0.86       |      0.48      |      0.91      |\n",
            "|              |            |        |                         |        |    [ 14   0]]    |                   |                |                |\n",
            "|      90      |    relu    |  adam  |      (100, 50, 30)      |  0.05  |    [[134   2]    |        0.86       |      0.47      |      0.89      |\n",
            "|              |            |        |                         |        |    [ 14   0]]    |                   |                |                |\n",
            "|      40      |  identity  | lbfgs  |      (120, 80, 40)      | 0.0001 |    [[136   0]    |        0.86       |      0.48      |      0.91      |\n",
            "|              |            |        |                         |        |    [ 14   0]]    |                   |                |                |\n",
            "+--------------+------------+--------+-------------------------+--------+------------------+-------------------+----------------+----------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machine"
      ],
      "metadata": {
        "id": "PUj2zqafawiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Support vector machine')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "  \n",
        "  '''Create Artificial Neural Network classifier'''\n",
        "  model1 = SVC()\n",
        "  model2 = SVC(kernel='sigmoid', C=100, gamma=1, random_state=85)\n",
        "  model3 = SVC(kernel='rbf', C=0.1, gamma=0.01, random_state=15)\n",
        "  model4 = SVC(kernel='linear', C=1, gamma=0.001, random_state=74)\n",
        "\n",
        "  '''Train and test'''\n",
        "  model1.fit(train_features, train_target)\n",
        "  model2.fit(train_features, train_target)\n",
        "  model3.fit(train_features, train_target)\n",
        "  model4.fit(train_features, train_target)\n",
        "\n",
        "  preds1 = model1.predict(test_features)\n",
        "  preds2 = model2.predict(test_features)\n",
        "  preds3 = model3.predict(test_features)\n",
        "  preds4 = model4.predict(test_features)\n",
        "\n",
        "  cr1 = confusion_matrix(test_target, preds1)\n",
        "  cr2 = confusion_matrix(test_target, preds2)\n",
        "  cr3 = confusion_matrix(test_target, preds3)\n",
        "  cr4 = confusion_matrix(test_target, preds4)\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "\n",
        "  f1_weighted1 = f1_score(test_target, preds1, average = 'weighted')\n",
        "  f1_weighted2 = f1_score(test_target, preds2, average = 'weighted')\n",
        "  f1_weighted3 = f1_score(test_target, preds3, average = 'weighted')\n",
        "  f1_weighted4 = f1_score(test_target, preds4, average = 'weighted')\n",
        "\n",
        "  f1_macro1 = f1_score(test_target, preds1, average = 'macro')\n",
        "  f1_macro2 = f1_score(test_target, preds2, average = 'macro')\n",
        "  f1_macro3 = f1_score(test_target, preds3, average = 'macro')\n",
        "  f1_macro4 = f1_score(test_target, preds4, average = 'macro')\n",
        "\n",
        "  f1_micro1 = f1_score(test_target, preds1, average = 'micro')\n",
        "  f1_micro2 = f1_score(test_target, preds2, average = 'micro')\n",
        "  f1_micro3 = f1_score(test_target, preds3, average = 'micro')\n",
        "  f1_micro4 = f1_score(test_target, preds4, average = 'micro')\n",
        "\n",
        "  f1_score_weighted1 = \"%.2f\"%round(f1_weighted1, 2)\n",
        "  f1_score_weighted2 = \"%.2f\"%round(f1_weighted2, 2)\n",
        "  f1_score_weighted3 = \"%.2f\"%round(f1_weighted3, 2)\n",
        "  f1_score_weighted4 = \"%.2f\"%round(f1_weighted4, 2)\n",
        "\n",
        "  f1_score_macro1 = \"%.2f\"%round(f1_macro1, 2)\n",
        "  f1_score_macro2 = \"%.2f\"%round(f1_macro2, 2)\n",
        "  f1_score_macro3 = \"%.2f\"%round(f1_macro3, 2)\n",
        "  f1_score_macro4 = \"%.2f\"%round(f1_macro4, 2)\n",
        "\n",
        "  f1_score_micro1 = \"%.2f\"%round(f1_micro1, 2)\n",
        "  f1_score_micro2 = \"%.2f\"%round(f1_micro2, 2)\n",
        "  f1_score_micro3 = \"%.2f\"%round(f1_micro3, 2)\n",
        "  f1_score_micro4 = \"%.2f\"%round(f1_micro4, 2)\n",
        "\n",
        "  head = PrettyTable(['random_state', 'c', 'gamma', 'kernel', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  head.add_row(['', '', '', '', cr1, f1_score_weighted1, f1_score_macro1, f1_score_micro1]) \n",
        "  head.add_row(['85', '100', '1', 'sigmoid', cr2, f1_score_weighted2, f1_score_macro2, f1_score_micro2]) \n",
        "  head.add_row(['15', '0.01', '0.01', 'rbf', cr3, f1_score_weighted3, f1_score_macro3, f1_score_micro3]) \n",
        "  head.add_row(['74', '1', '0.001', 'linear', cr4, f1_score_weighted4, f1_score_macro4, f1_score_micro4]) \n",
        "  print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PleHBPwRawvv",
        "outputId": "f6d7dcd0-df6a-40bd-f394-a7eae2a62e41"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support vector machine\n",
            "Project: oryx\n",
            "+--------------+------+-------+---------+------------------+-------------------+----------------+----------------+\n",
            "| random_state |  c   | gamma |  kernel | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+--------------+------+-------+---------+------------------+-------------------+----------------+----------------+\n",
            "|              |      |       |         |    [[134   0]    |        0.84       |      0.47      |      0.89      |\n",
            "|              |      |       |         |    [ 16   0]]    |                   |                |                |\n",
            "|      85      | 100  |   1   | sigmoid |    [[134   0]    |        0.84       |      0.47      |      0.89      |\n",
            "|              |      |       |         |    [ 16   0]]    |                   |                |                |\n",
            "|      15      | 0.01 |  0.01 |   rbf   |    [[134   0]    |        0.84       |      0.47      |      0.89      |\n",
            "|              |      |       |         |    [ 16   0]]    |                   |                |                |\n",
            "|      74      |  1   | 0.001 |  linear |    [[129   5]    |        0.83       |      0.46      |      0.86      |\n",
            "|              |      |       |         |    [ 16   0]]    |                   |                |                |\n",
            "+--------------+------+-------+---------+------------------+-------------------+----------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision tree"
      ],
      "metadata": {
        "id": "3xYWfJCxbARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Decision tree')\n",
        "projects = ['oryx']\n",
        "\n",
        "for project in projects:\n",
        "  print(f'Project: {project}')\n",
        "\n",
        "  '''Read data from CSV with Pandas'''\n",
        "  _file =f\"drive/MyDrive/subtract/{project}/class.csv\"\n",
        "  cols = list(pd.read_csv(_file, nrows =1).dropna(axis='columns', how='all'))\n",
        "\n",
        "  df = pd.read_csv(_file, usecols =cols)\n",
        "  df.pop('LongName')\n",
        "  df.pop('Hash')\n",
        "  df = df.T.drop_duplicates().T\n",
        "\n",
        "  '''Split into train and test with numpy (0.75 train, 0.25 test)'''\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train, test = train_test_split(df, test_size=0.25)\n",
        "\n",
        "  df=(df-df.mean())/df.std()\n",
        "\n",
        "  test_target = test.pop('Number of Bugs')\n",
        "  test_features = test\n",
        " \n",
        "  train_target = train.pop('Number of Bugs')\n",
        "  train_features = train\n",
        "\n",
        "  head = PrettyTable(['random_state', 'max_depth', 'confusion_matrix', 'f1_score_weighted', 'f1_score_macro', 'f1_score_micro']) \n",
        "  \n",
        "  max_depth_range = list(range(1, 15))\n",
        "  for depth in max_depth_range:\n",
        "\n",
        "    '''Create decision tree classifier'''    \n",
        "    model = tree.DecisionTreeClassifier(max_depth = depth,  random_state = 90)\n",
        "  \n",
        "    '''Train and test'''\n",
        "    model.fit(train_features, train_target)\n",
        "    preds = model.predict(test_features)\n",
        "\n",
        "    cr = confusion_matrix(test_target, preds)\n",
        "\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    f1_weighted = f1_score(test_target, preds, average = 'weighted')\n",
        "    f1_macro = f1_score(test_target, preds, average = 'macro')\n",
        "    f1_micro = f1_score(test_target, preds, average = 'micro')\n",
        "\n",
        "    f1_score_weighted = \"%.2f\"%round(f1_weighted, 2)\n",
        "    f1_score_macro = \"%.2f\"%round(f1_macro, 2)\n",
        "    f1_score_micro = \"%.2f\"%round(f1_micro, 2)\n",
        "\n",
        "    head.add_row(['90', depth, cr, f1_score_weighted, f1_score_macro, f1_score_micro])\n",
        "  print(head)\n",
        "  \n"
      ],
      "metadata": {
        "id": "JLoDYAa2bAzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecce5b07-a272-4b59-d999-d637eb67560c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree\n",
            "Project: oryx\n",
            "+--------------+-----------+------------------+-------------------+----------------+----------------+\n",
            "| random_state | max_depth | confusion_matrix | f1_score_weighted | f1_score_macro | f1_score_micro |\n",
            "+--------------+-----------+------------------+-------------------+----------------+----------------+\n",
            "|      90      |     1     |    [[134   0]    |        0.84       |      0.47      |      0.89      |\n",
            "|              |           |    [ 16   0]]    |                   |                |                |\n",
            "|      90      |     2     |    [[134   0]    |        0.84       |      0.47      |      0.89      |\n",
            "|              |           |    [ 16   0]]    |                   |                |                |\n",
            "|      90      |     3     |    [[133   1]    |        0.87       |      0.58      |      0.90      |\n",
            "|              |           |    [ 14   2]]    |                   |                |                |\n",
            "|      90      |     4     |    [[129   5]    |        0.85       |      0.55      |      0.87      |\n",
            "|              |           |    [ 14   2]]    |                   |                |                |\n",
            "|      90      |     5     |    [[127   7]    |        0.85       |      0.58      |      0.87      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     6     |    [[127   7]    |        0.85       |      0.58      |      0.87      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     7     |    [[126   8]    |        0.86       |      0.61      |      0.87      |\n",
            "|              |           |    [ 12   4]]    |                   |                |                |\n",
            "|      90      |     8     |    [[123  11]    |        0.83       |      0.52      |      0.83      |\n",
            "|              |           |    [ 14   2]]    |                   |                |                |\n",
            "|      90      |     9     |    [[124  10]    |        0.84       |      0.56      |      0.85      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     10    |    [[123  11]    |        0.84       |      0.56      |      0.84      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     11    |    [[118  16]    |        0.82       |      0.56      |      0.81      |\n",
            "|              |           |    [ 12   4]]    |                   |                |                |\n",
            "|      90      |     12    |    [[119  15]    |        0.82       |      0.54      |      0.81      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     13    |    [[117  17]    |        0.81       |      0.53      |      0.80      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "|      90      |     14    |    [[117  17]    |        0.81       |      0.53      |      0.80      |\n",
            "|              |           |    [ 13   3]]    |                   |                |                |\n",
            "+--------------+-----------+------------------+-------------------+----------------+----------------+\n"
          ]
        }
      ]
    }
  ]
}